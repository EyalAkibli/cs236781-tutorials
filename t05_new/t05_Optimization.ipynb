{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "$$\n",
    "\n",
    "# CS236781: Deep Learning\n",
    "# Tutorial 5: Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will cover:  **TODO**\n",
    "\n",
    "- Backpropagation\n",
    "- Optimization\n",
    "- Automatic differentiation\n",
    "- PyTorch backward functions\n",
    "- Bi-level differentiable optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theory Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descent-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we have seen, training deep neural network is performed iteratively using descent-based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The general scheme is,\n",
    "\n",
    "1. Initialize parameters to some $\\vec{\\Theta}^0 \\in \\set{R}^P$, and set $k\\leftarrow 0$.\n",
    "2. While not converged:\n",
    "    1. Choose a direction $\\vec{d}^k\\in\\set{R}^P$\n",
    "    2. Choose a step size $\\eta_k\\in\\set{R}$\n",
    "    3. Update: $\\vec{\\Theta}^{k+1} \\leftarrow \\vec{\\Theta}^k + \\eta_k \\vec{d}^k$\n",
    "    4. $k\\leftarrow k+1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which descent direction to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one which maximally decreases the loss function $L(\\vec{\\Theta})$:\n",
    "\n",
    "$$\n",
    "\\vec{d} =\\arg\\min_{\\vec{d'}} L(\\vec{\\Theta}+\\vec{d'})-L(\\vec{\\Theta})\n",
    "\\approx\n",
    "\\arg\\min_{\\vec{d'}}\\nabla L(\\vec{\\Theta})^\\top\\vec{d'}, \\\n",
    "\\mathrm{s.t.} \\norm{\\vec{d}}_p=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of norm determines $\\vec{d}$. For example,\n",
    "- $p=1$: Coordinate descent: direction of the largest gradient component.\n",
    "- $p=2$: Gradient descent: $\\vec{d}=-\\nabla L(\\vec{\\Theta})$.\n",
    "\n",
    "|$p=1$|$p=2$|\n",
    "|---|---|\n",
    "|<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e3/Coordinate_descent.svg\" width=\"300\" /> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/ff/Gradient_descent.svg\" width=\"300\" />| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawbacks and mitigations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Susceptible to initialization**\n",
    "\n",
    "Initializing near local minima can prevent finding better ones.\n",
    "\n",
    "<center><img src=\"imgs/sgd-init.png\" width=\"600\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use stochastic gradient to get a different loss surface every iteration.\n",
    "\n",
    "\n",
    "<center><img src=\"imgs/sgd-loss.png\" width=\"500\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitive to learning rate**\n",
    "\n",
    "<center><img src=\"imgs/sgd-lr.png\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Line search (1D minimization):\n",
    "$$\n",
    "\\eta_k = \\arg\\min_{\\eta'} L(\\vec{\\Theta}^k+\\eta'\\vec{d}^k)\n",
    "$$\n",
    "\n",
    "- Adaptive LR optimizers, e.g. Adam\n",
    "\n",
    "- LR scheduling\n",
    "<center><img src=\"imgs/sgd-lr-schedule.png\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zig-zags in narrow \"ravines\"**\n",
    "\n",
    "<center><img src=\"imgs/sgd-zigzag.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Momentum: Use previous gradients to build \"speed\" in the common direction and cancel-out oscillations in opposite directions.\n",
    "\n",
    "- BatchNorm: Normalizes activations to zero-mean and unit variance (reduces curvature)\n",
    "\n",
    "- Second-order methods: Use quadratic local approximation of the loss surface, instead of linear.\n",
    "    - Newton's method: $\\vec{d}_k=\\mat{H}_k^{-1}\\vec{g}_k = \\nabla^2 L(\\vec{\\Theta}_k)^{-1}\\nabla L(\\vec{\\Theta}_k)$.\n",
    "    - Quasi-Newton methods which use some estimate of the Hessian based on first-order information (e.g. BFGS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The back-propagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above optimization methods have a crucial thing in common: They require calculation of gradients of the loss w.r.t. to the parameters.\n",
    "\n",
    "In practical settings when training neural networks we have many different parameters tensors we would like to update separately. Thus, we require the gradient of the loss w.r.t. each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back-propagation is an efficient way to calculate these gradients using the chain rule.\n",
    "\n",
    "We represent the application of a model as a **computation graph**.\n",
    "For example, a simple linear regression model can be represented as:\n",
    "\n",
    "<center><img src=\"imgs/backprop-graph.png\" width=\"350\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that in this graph we have $N$ variables $\\vec{v}^i,\\ 1\\leq i \\leq N$  and functions $f_i$ which compute them from other variables.\n",
    "\n",
    "The graph is directional, thus assume $\\vec{v}^1, \\vec{v}^2,\\dots,\\vec{v}^N$ represents a topological order of the graph (parents before children).\n",
    "\n",
    "Define also the notation $\\delta\\vec{v}\\triangleq \\pderiv{L}{\\vec{v}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward pass can therefore we written as:\n",
    "\n",
    "1. For $i=1,2,\\dots,N$:\n",
    "  1. Graph parents of current node: $$\\mathcal{P}_i \\leftarrow \\left\\{\\vec{v}^j ~\\middle\\vert~ \\vec{v}^j \\text{ parent of } \\vec{v}^i\\right\\}$$ \n",
    "  2. Evaluate function at current node: $$\\vec{v}^i\\leftarrow f_i(\\mathcal{P}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the backward pass we traverse the graph in reverse and apply the chain rule:\n",
    "\n",
    "1. Set $\\delta\\vec{v}^N=1$.\n",
    "2. For $i=N,N-1,\\dots,1$:\n",
    "  1. Graph children of current node: $$\\mathcal{C}_i \\leftarrow \\left\\{\\vec{v}^j ~\\middle\\vert~ \\vec{v}^j \\text{ child of } \\vec{v}^i\\right\\}$$  \n",
    "  2. Chain rule: $$\\delta\\vec{v}^i\\leftarrow \\sum_{\\vec{v}^j\\in\\mathcal{C}_i} \\delta\\vec{v}^j\\pderiv{\\vec{v}^j}{\\vec{v}^i}$$\n",
    "  \n",
    "Notes:\n",
    "1. The expression $\\delta\\vec{v}^j\\pderiv{\\vec{v}^j}{\\vec{v}^i}$ is a \"vector\"-Jacobian product (VJP).\n",
    "2. When a computation node's output is used by more than one other node (more than one child in the graph), we sum the incoming gradients from these children. This again arises directly from the chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation easily lends itself to a modular and efficient implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularity:\n",
    "- Nodes in the computation graph only need to know how to calculate their own derivatives.\n",
    "- This is then passed to the parent nodes, which can do the same.\n",
    "\n",
    "\n",
    "<center><img src=\"imgs/backprop-modular.png\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency:\n",
    "\n",
    "- Only need to compute each $\\delta\\vec{v}^i$ once.\n",
    "- No need to construct the Jacobian, instead calculate the VJP directly since that's what we actually need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern automatic-differentiation packages such as PyTorch's `autograd` utilize exactly these tricks to implement backprop in an extremely powerful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Custom automatic differentiation with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now learn how to extend PyTorch's `autograd` by defining our own custom nodes in the computation graph.\n",
    "\n",
    "Lets first introduce a cousin of ReLU, the Exponential-Linear Unit (ELU) activation function:\n",
    "\n",
    "$$\n",
    "f(z) =\n",
    "\\begin{cases}\n",
    "z, & z > 0\\\\\n",
    "\\alpha \\left(e^{z}-1\\right) & z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pretend PyTorch does not include this activation function and implement a custom version ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torchviz\n",
    "\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll implement just the actual computation as a standalone function so that we can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu_forward(z: Tensor, alpha: float):\n",
    "    elu_positive = z\n",
    "    elu_negative = alpha * (torch.exp(z) - 1)\n",
    "    elu_output = torch.where(z>0, elu_positive, elu_negative)\n",
    "    return elu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick visualization to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.linspace(-5, 5, steps=1000)\n",
    "plt.plot(z.numpy(), torch.relu(z).numpy(), label='ReLU(z)', linewidth=5);\n",
    "plt.plot(z.numpy(), elu_forward(z, alpha=0.5).numpy(), label='ELU(z)', linewidth=2); plt.legend(); plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll wrap it as an `nn.Module` so that we can use it as a layer in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELU(torch.nn.Module):\n",
    "    \"\"\" ELU Activation layer \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, z: Tensor):\n",
    "        return elu_forward(z, self.alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as usual, we can look at the resulting computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"142pt\" height=\"264pt\"\n",
       " viewBox=\"0.00 0.00 141.97 264.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-260 137.97,-260 137.97,4 -4,4\"/>\n",
       "<!-- 140636202748608 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140636202748608</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"103.44,-20 -0.15,-20 -0.15,0 103.44,0 103.44,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.65\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\">SWhereBackward</text>\n",
       "</g>\n",
       "<!-- 140636202748656 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140636202748656</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.65,-256 23.65,-256 23.65,-224 77.65,-224 77.65,-256\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.65\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"50.65\" y=\"-230.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 140636202748656&#45;&gt;140636202748608 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140636202748656&#45;&gt;140636202748608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.95,-223.62C41.54,-213.62 37.52,-200.22 35.65,-188 33.48,-173.85 34.33,-57.71 34.65,-56 36.29,-46.97 39.66,-37.41 42.96,-29.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"46.28,-30.59 47.12,-20.03 39.87,-27.76 46.28,-30.59\"/>\n",
       "</g>\n",
       "<!-- 140636202749040 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140636202749040</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"128.62,-188 44.67,-188 44.67,-168 128.62,-168 128.62,-188\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.65\" y=\"-174.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpBackward</text>\n",
       "</g>\n",
       "<!-- 140636202748656&#45;&gt;140636202749040 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140636202748656&#45;&gt;140636202749040</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.73,-223.86C64.63,-215.69 70.72,-205.55 75.86,-196.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.01,-198.53 81.15,-188.15 73.01,-194.93 79.01,-198.53\"/>\n",
       "</g>\n",
       "<!-- 140636202748704 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140636202748704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"133.8,-76 43.5,-76 43.5,-56 133.8,-56 133.8,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"88.65\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140636202748704&#45;&gt;140636202748608 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140636202748704&#45;&gt;140636202748608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M82.2,-55.59C77.11,-48.16 69.86,-37.58 63.69,-28.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.56,-26.57 58.02,-20.3 60.78,-30.53 66.56,-26.57\"/>\n",
       "</g>\n",
       "<!-- 140636202748992 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140636202748992</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"133.47,-132 43.83,-132 43.83,-112 133.47,-112 133.47,-132\"/>\n",
       "<text text-anchor=\"middle\" x=\"88.65\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140636202748992&#45;&gt;140636202748704 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140636202748992&#45;&gt;140636202748704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M88.65,-111.59C88.65,-104.7 88.65,-95.1 88.65,-86.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.15,-86.3 88.65,-76.3 85.15,-86.3 92.15,-86.3\"/>\n",
       "</g>\n",
       "<!-- 140636202749040&#45;&gt;140636202748992 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140636202749040&#45;&gt;140636202748992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.99,-167.59C87.25,-160.7 87.61,-151.1 87.92,-142.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.43,-142.42 88.3,-132.3 84.43,-142.16 91.43,-142.42\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe86ae84a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elu = ELU(alpha=0.5)\n",
    "z = torch.tensor([-2., -1, 0, 1, 2, 3], requires_grad=True)\n",
    "torchviz.make_dot(elu(z), params=dict(z=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the computation graph accurately represents the various basic mathematical operations performed bby our `elu_forward` function.\n",
    "\n",
    "But what if we want to define the entire ELU operarion as one node in the graph?\n",
    "This can be useful e.g. for performance reasons.\n",
    "\n",
    "But how can we accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to use a lower-level PyTorch API, `autograd.Function`\n",
    "which allows us to define a function in terms of both it's forwards pass\n",
    "(the regular output computation), and it's **backward** pass\n",
    "(the gradient w.r.t. all it's inputs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the PyTorch docs:\n",
    "    \n",
    "    Every operation performed on Tensor s creates a new Function object, that performs the computation, and records that it happened. The history is retained in the form of a DAG of functions, with edges denoting data dependencies (input <- output). Then, when backward is called, the graph is processed in the topological ordering, by calling backward() methods of each Function object, and passing returned gradients on to next Function s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first calculate the simple analytic derivative of the ELU function:\n",
    "$$\n",
    "\\pderiv{f(z)}{z} = f'(z) = \n",
    "\\begin{cases}\n",
    "1, & z > 0\\\\\n",
    "\\alpha e^{z} & z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to figure out how to compute the vector-Jacobian product efficiently.\n",
    "Note that for any **elementwise** operation, $\\vec{y}=f(\\vec{x}),\\ f:\\set{R}^n\\rightarrow\\set{R}^n$, we can write the Jacobian as\n",
    "\n",
    "$$\n",
    "\\pderiv{\\vec{y}}{\\vec{x}} = \\pmatrix{\n",
    "\\ddots & \\vdots & \\\\\n",
    "\\cdots & \\pderiv{y_i}{x_j} & \\cdots \\\\\n",
    "& \\vdots & \\ddots\\\\\n",
    "}\n",
    "=\n",
    "\\pmatrix{\n",
    "f'(x_1) &  &  \\\\\n",
    "  & f'(x_i) &  \\\\\n",
    "& & f'(x_n)\\\\\n",
    "}\n",
    "= \\diag\\{{f'(\\vec{x})}\\}\n",
    "$$\n",
    "\n",
    "And it follows that the VJP can be computed simply:\n",
    "$$\n",
    "\\delta \\vec{x} = \\delta{\\vec{y}}\\pderiv{\\vec{y}}{\\vec{x}} = \\delta{\\vec{y}} \\odot f'(\\vec{x}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, equipped with the expression for the VJP, we can proceed to implement the Function object representing ELU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELUFunction(autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, z: Tensor, alpha: float):\n",
    "        elu = elu_forward(z, alpha) # Regular forward pass computation from before\n",
    "        ctx.save_for_backward(z)    # Tensors should be saved using this method\n",
    "        ctx.alpha = alpha           # other properties can bbe saved like so\n",
    "        return elu\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        z, = ctx.saved_tensors\n",
    "        alpha = ctx.alpha\n",
    "        \n",
    "        # Calculate diagonal of d(elu(z))/dz\n",
    "        grad_positive = torch.ones_like(z)\n",
    "        grad_negative = alpha * torch.exp(z)\n",
    "        \n",
    "        # Note: This is not the full Jacobian\n",
    "        grad_elu = torch.where(z>0, grad_positive, grad_negative)\n",
    "        \n",
    "        # Gradient of the loss w.r.t. our output\n",
    "        δ_elu = grad_output\n",
    "        \n",
    "        # Calcualte δz = d(elu(z))/dz * δ_elu\n",
    "        # Note: elementwise multiplication equivalant to vector-Jacobian product\n",
    "        print(f'{grad_elu.shape=}, {δ_elu.shape=}')\n",
    "        δz = grad_elu * δ_elu\n",
    "        return δz, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this custom `Function` either directly or as part of a layer.\n",
    "\n",
    "For example, here's an ELU layer using our custom backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELUCustom(torch.nn.Module):\n",
    "    \"\"\" ELU Layer with a custom backward pass \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, z: Tensor):\n",
    "        # Function.apply() invokes the forward pass\n",
    "        return ELUFunction.apply(z, self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"139pt\" height=\"96pt\"\n",
       " viewBox=\"0.00 0.00 138.64 96.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 92)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-92 134.64,-92 134.64,4 -4,4\"/>\n",
       "<!-- 140636202469264 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140636202469264</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.46,-20 0.18,-20 0.18,0 130.46,0 130.46,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.32\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 140636202747792 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140636202747792</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"56.32,-88 2.32,-88 2.32,-56 56.32,-56 56.32,-88\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.32\" y=\"-74.4\" font-family=\"Times,serif\" font-size=\"12.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"29.32\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 140636202747792&#45;&gt;140636202469264 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140636202747792&#45;&gt;140636202469264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.4,-55.86C43.31,-47.69 49.39,-37.55 54.53,-28.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.68,-30.53 59.83,-20.15 51.68,-26.93 57.68,-30.53\"/>\n",
       "</g>\n",
       "<!-- 140636202732032 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140636202732032</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"128.32,-82 74.32,-82 74.32,-62 128.32,-62 128.32,-82\"/>\n",
       "<text text-anchor=\"middle\" x=\"101.32\" y=\"-68.4\" font-family=\"Times,serif\" font-size=\"12.00\">(6)</text>\n",
       "</g>\n",
       "<!-- 140636202732032&#45;&gt;140636202469264 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140636202732032&#45;&gt;140636202469264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.85,-61.89C90.62,-53.17 82.58,-39.77 76.06,-28.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.98,-26.97 70.84,-20.2 72.98,-30.57 78.98,-26.97\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe86ae84e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elu_custom = ELUCustom(alpha=0.5)\n",
    "z = torch.tensor([-2., -1, 0, 1, 2, 3], requires_grad=True)\n",
    "torchviz.make_dot(elu_custom(z), params=dict(z=z),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only tested the forward pass. Let's now put our custom layer in the context of a larger model and see that we can backprop through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_mlp = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=512, out_features=1024),\n",
    "    ELUCustom(alpha=0.01),\n",
    "    torch.nn.Linear(in_features=1024, out_features=1024),\n",
    "    ELUCustom(alpha=0.01),\n",
    "    torch.nn.Linear(in_features=1024, out_features=10),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"441pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 440.99 548.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 544)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-544 436.99,-544 436.99,4 -4,4\"/>\n",
       "<!-- 140636202794336 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140636202794336</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"326.97,-20 229.03,-20 229.03,0 326.97,0 326.97,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"278\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140636202794048 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140636202794048</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"330.81,-76 225.19,-76 225.19,-56 330.81,-56 330.81,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"278\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\">SoftmaxBackward</text>\n",
       "</g>\n",
       "<!-- 140636202794048&#45;&gt;140636202794336 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140636202794048&#45;&gt;140636202794336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278,-55.59C278,-48.7 278,-39.1 278,-30.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"281.5,-30.3 278,-20.3 274.5,-30.3 281.5,-30.3\"/>\n",
       "</g>\n",
       "<!-- 140636202794000 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140636202794000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"329.98,-132 226.02,-132 226.02,-112 329.98,-112 329.98,-132\"/>\n",
       "<text text-anchor=\"middle\" x=\"278\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140636202794000&#45;&gt;140636202794048 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140636202794000&#45;&gt;140636202794048</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278,-111.59C278,-104.7 278,-95.1 278,-86.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"281.5,-86.3 278,-76.3 274.5,-86.3 281.5,-86.3\"/>\n",
       "</g>\n",
       "<!-- 140636202794768 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140636202794768</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"195,-200 141,-200 141,-168 195,-168 195,-200\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-186.4\" font-family=\"Times,serif\" font-size=\"12.00\">4.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-174.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140636202794768&#45;&gt;140636202794000 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140636202794768&#45;&gt;140636202794000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.19,-168.17C212.69,-158.62 235.29,-146.3 252.45,-136.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.26,-139.93 261.37,-132.07 250.91,-133.79 254.26,-139.93\"/>\n",
       "</g>\n",
       "<!-- 140636202469472 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140636202469472</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"343.14,-194 212.86,-194 212.86,-174 343.14,-174 343.14,-194\"/>\n",
       "<text text-anchor=\"middle\" x=\"278\" y=\"-180.4\" font-family=\"Times,serif\" font-size=\"12.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 140636202469472&#45;&gt;140636202794000 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140636202469472&#45;&gt;140636202794000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278,-173.89C278,-165.52 278,-152.84 278,-142.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"281.5,-142.2 278,-132.2 274.5,-142.2 281.5,-142.2\"/>\n",
       "</g>\n",
       "<!-- 140636202794912 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140636202794912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"243.98,-262 140.02,-262 140.02,-242 243.98,-242 243.98,-262\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140636202794912&#45;&gt;140636202469472 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140636202794912&#45;&gt;140636202469472</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.96,-241.82C217.95,-231.09 241.33,-213.14 258.08,-200.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.34,-202.96 266.14,-194.1 256.08,-197.41 260.34,-202.96\"/>\n",
       "</g>\n",
       "<!-- 140636202794960 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140636202794960</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"109,-336 55,-336 55,-304 109,-304 109,-336\"/>\n",
       "<text text-anchor=\"middle\" x=\"82\" y=\"-322.4\" font-family=\"Times,serif\" font-size=\"12.00\">2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"82\" y=\"-310.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 140636202794960&#45;&gt;140636202794912 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140636202794960&#45;&gt;140636202794912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.24,-303.86C125.49,-292.9 150.01,-278.19 167.98,-267.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.94,-270.32 176.71,-262.17 166.34,-264.32 169.94,-270.32\"/>\n",
       "</g>\n",
       "<!-- 140636202468848 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140636202468848</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"257.14,-330 126.86,-330 126.86,-310 257.14,-310 257.14,-330\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-316.4\" font-family=\"Times,serif\" font-size=\"12.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 140636202468848&#45;&gt;140636202794912 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140636202468848&#45;&gt;140636202794912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192,-309.82C192,-300.17 192,-284.69 192,-272.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.5,-272.1 192,-262.1 188.5,-272.1 195.5,-272.1\"/>\n",
       "</g>\n",
       "<!-- 140636202791600 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140636202791600</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154.98,-398 51.02,-398 51.02,-378 154.98,-378 154.98,-398\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-384.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140636202791600&#45;&gt;140636202468848 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140636202791600&#45;&gt;140636202468848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.38,-377.82C129.85,-367.09 154.05,-349.14 171.38,-336.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.78,-338.87 179.73,-330.1 169.61,-333.24 173.78,-338.87\"/>\n",
       "</g>\n",
       "<!-- 140636202794384 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140636202794384</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-472 0,-472 0,-440 54,-440 54,-472\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\">0.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-446.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 140636202794384&#45;&gt;140636202791600 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140636202794384&#45;&gt;140636202791600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.63,-439.69C56.6,-429.3 72.4,-415.57 84.54,-405.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.02,-407.52 92.27,-398.32 82.43,-402.23 87.02,-407.52\"/>\n",
       "</g>\n",
       "<!-- 140636202794144 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140636202794144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"134.49,-472 71.51,-472 71.51,-440 134.49,-440 134.49,-472\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\">x</text>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-446.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10, 512)</text>\n",
       "</g>\n",
       "<!-- 140636202794144&#45;&gt;140636202791600 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140636202794144&#45;&gt;140636202791600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-439.69C103,-430.4 103,-418.44 103,-408.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-408.32 103,-398.32 99.5,-408.32 106.5,-408.32\"/>\n",
       "</g>\n",
       "<!-- 140636202793184 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140636202793184</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"223.97,-466 152.03,-466 152.03,-446 223.97,-446 223.97,-466\"/>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-452.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140636202793184&#45;&gt;140636202791600 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140636202793184&#45;&gt;140636202791600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M176.18,-445.82C162.35,-435.09 139.24,-417.14 122.69,-404.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.76,-401.47 114.72,-398.1 120.47,-407 124.76,-401.47\"/>\n",
       "</g>\n",
       "<!-- 140636202791408 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140636202791408</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"225.49,-540 150.51,-540 150.51,-508 225.49,-508 225.49,-540\"/>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-526.4\" font-family=\"Times,serif\" font-size=\"12.00\">0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-514.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024, 512)</text>\n",
       "</g>\n",
       "<!-- 140636202791408&#45;&gt;140636202793184 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140636202791408&#45;&gt;140636202793184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188,-507.69C188,-498.4 188,-486.44 188,-476.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.5,-476.32 188,-466.32 184.5,-476.32 191.5,-476.32\"/>\n",
       "</g>\n",
       "<!-- 140636202711744 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140636202711744</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"238.99,-398 173.01,-398 173.01,-378 238.99,-378 238.99,-398\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-384.4\" font-family=\"Times,serif\" font-size=\"12.00\">(10, 1024)</text>\n",
       "</g>\n",
       "<!-- 140636202711744&#45;&gt;140636202468848 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140636202711744&#45;&gt;140636202468848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.05,-377.82C201.98,-368.07 198.66,-352.37 196.02,-339.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.43,-339.16 193.93,-330.1 192.58,-340.61 199.43,-339.16\"/>\n",
       "</g>\n",
       "<!-- 140636202794240 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140636202794240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"346.97,-330 275.03,-330 275.03,-310 346.97,-310 346.97,-330\"/>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-316.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140636202794240&#45;&gt;140636202794912 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140636202794240&#45;&gt;140636202794912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.45,-309.82C274.47,-298.74 240.65,-279.98 217.37,-267.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.85,-263.89 208.41,-262.1 215.45,-270.01 218.85,-263.89\"/>\n",
       "</g>\n",
       "<!-- 140636202793280 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140636202793280</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"351.49,-404 270.51,-404 270.51,-372 351.49,-372 351.49,-404\"/>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-390.4\" font-family=\"Times,serif\" font-size=\"12.00\">2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-378.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024, 1024)</text>\n",
       "</g>\n",
       "<!-- 140636202793280&#45;&gt;140636202794240 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140636202793280&#45;&gt;140636202794240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311,-371.69C311,-362.4 311,-350.44 311,-340.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.5,-340.32 311,-330.32 307.5,-340.32 314.5,-340.32\"/>\n",
       "</g>\n",
       "<!-- 140636202700096 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>140636202700096</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"327.99,-262 262.01,-262 262.01,-242 327.99,-242 327.99,-262\"/>\n",
       "<text text-anchor=\"middle\" x=\"295\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\">(10, 1024)</text>\n",
       "</g>\n",
       "<!-- 140636202700096&#45;&gt;140636202469472 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140636202700096&#45;&gt;140636202469472</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.64,-241.82C290.12,-232.07 286.08,-216.37 282.88,-203.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.23,-202.91 280.34,-194.1 279.45,-204.66 286.23,-202.91\"/>\n",
       "</g>\n",
       "<!-- 140636202794816 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>140636202794816</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"432.97,-194 361.03,-194 361.03,-174 432.97,-174 432.97,-194\"/>\n",
       "<text text-anchor=\"middle\" x=\"397\" y=\"-180.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140636202794816&#45;&gt;140636202794000 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140636202794816&#45;&gt;140636202794000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.93,-173.89C359.24,-163.96 327.55,-147.98 304.93,-136.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.36,-133.38 295.85,-132 303.21,-139.63 306.36,-133.38\"/>\n",
       "</g>\n",
       "<!-- 140636202793328 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>140636202793328</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"431.49,-268 362.51,-268 362.51,-236 431.49,-236 431.49,-268\"/>\n",
       "<text text-anchor=\"middle\" x=\"397\" y=\"-254.4\" font-family=\"Times,serif\" font-size=\"12.00\">4.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"397\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10, 1024)</text>\n",
       "</g>\n",
       "<!-- 140636202793328&#45;&gt;140636202794816 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>140636202793328&#45;&gt;140636202794816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M397,-235.69C397,-226.4 397,-214.44 397,-204.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"400.5,-204.32 397,-194.32 393.5,-204.32 400.5,-204.32\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe86ae8f670>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 512, requires_grad=True)\n",
    "torchviz.make_dot(elu_mlp(x).mean(), params=dict(list(elu_mlp.named_parameters()) + [('x', x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the backward pass and make sure we have gradients on all parameter tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_elu.shape=torch.Size([10, 1024]), δ_elu.shape=torch.Size([10, 1024])\n",
      "grad_elu.shape=torch.Size([10, 1024]), δ_elu.shape=torch.Size([10, 1024])\n",
      "0.weight 3.8951057490521634e-07\n",
      "0.bias 1.5102544992373623e-08\n",
      "2.weight 5.098933115732507e-07\n",
      "2.bias 3.209331467246557e-08\n",
      "4.weight 4.6191954083951714e-07\n",
      "4.bias 5.746612075085977e-08\n"
     ]
    }
   ],
   "source": [
    "l = torch.sum(elu_mlp(x))\n",
    "l.backward()\n",
    "\n",
    "for name, param in elu_mlp.named_parameters():\n",
    "    print(f\"{name} {torch.norm(param.grad).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Differentiable Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll tackle a more interesting use-case for defining our custom backward functions: differentiating though an inner optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to solve an inner optimization problem as part of our model, while the parameters of the inner problem are also optimized by the end-to-end optimization of the entire model?\n",
    "\n",
    "<center><img src=\"imgs/bilevel.png\" width=\"600\"/></center>\n",
    "\n",
    "Training such a network end-to-end means we're trying to find:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\vec{\\Theta}^\\ast\n",
    "&=\n",
    "\\arg\\min_{\\vec{\\Theta}} \\E[(\\vec{x},\\vec{y})\\sim D]{\\mathcal{L}(\\vec{y}, \\hat{\\vec{y}})}\\\\\n",
    "&=\n",
    "\\arg\\min_{\\vec{\\Theta}} \\E[(\\vec{x},\\vec{y})\\sim D]{\n",
    "\\mathcal{L}(\\vec{y}, \\arg\\min_{\\vec{y}} f(\\vec{y}, h_{\\vec{\\Theta}}(\\vec{x}) )\n",
    "}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This type of setting is also known as a bi-level optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the perspective of the inner problem, $\\vec{z}$ is a \"fixed\" parameter. \n",
    "\n",
    "However, from the perspective of end-to-end training, we're optimizing $\\vec{\\Theta}$ in order to reduce the final loss.\n",
    "\n",
    "Therefore, we can view this as learning to parameterize the inner task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need in order to train such a model end-to-end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we must find a way to calculate a VJP, in this case:\n",
    "$$\n",
    "\\delta \\vec{z} = \\pderiv{\\hat{\\vec{y}}}{\\vec{z}}\\ \\delta\\hat{\\vec{y}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that $\\vec{y}=\\arg\\min_{\\vec{y}'}f(\\vec{y}', \\vec{z})$.\n",
    "\n",
    "Since $\\vec{y}$ is a minimizer of the function $f$, the necessary optimality condition\n",
    "must hold: $$\\nabla_{y}f(y, z)=0.$$\n",
    "\n",
    "If we then perturb $\\vec{z}$ by $d\\vec{z}$, we'll get a slightly different minimizer, $\\vec{y}+d\\vec{y}$. Thus also,\n",
    "\n",
    "$$\\nabla_{y}f(y+dy, z+dz)=0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a first-order Taylor expansion of $\\nabla_{y}f$ around the point $(y, z)$:\n",
    "\n",
    "$$\n",
    "\\nabla_{y}f(y+dy, z+dz) \\approx \\nabla_{y}f(y, z) + \\nabla^{2}_{yy}f(y,z)dy + \\nabla^{2}_{yz}f(y, z)dz = 0.\n",
    "$$\n",
    "\n",
    "Since $\\nabla_{y}f(y, z)=0$, we rearrange to obtain:\n",
    "\n",
    "$$\n",
    "\\nabla^{2}_{yy}f(y,z)dy = -\\nabla^{2}_{yz}f(y, z)dz.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll denote the Hessians as $\\mat{K}=\\nabla^{2}_{yy}f(y,z)$ and $\\mat{R}=\\nabla^{2}_{yz}f(y, z)$. We then obtain,\n",
    "\n",
    "$$\n",
    "\\mat{K}d\\vec{y}=-\\mat{R}d\\vec{z}\\Longrightarrow d\\vec{y}=-\\mat{K}^{-1}\\mat{R}d\\vec{z}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation means that we have found a linear relationship between the change in the function value, $d\\vec{y}$ and the change in the argument value, $d\\vec{z}$.\n",
    "This linear relationship must be, by definition, related to the gradient of $\\vec{y}$ w.r.t. $\\vec{z}$.\n",
    "\n",
    "Writing the above as an inner product, we have $$d\\vec{y}=\\ip{\\mattr{R}\\mat{K^{-T}}}{d\\vec{z}}{}.$$\n",
    "\n",
    "Note that $\\mat{K}$ is a Hessian, therefore symmetric and we can drop the transpose.\n",
    "\n",
    "Finally, by the \"outer\" definition of the gradient we see that $$\\pderiv{\\vec{y}}{\\vec{z}}=\\mattr{R}\\mat{K^{-1}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to our VJP: we need \n",
    "$$\n",
    "\\delta \\vec{z} =  \\pderiv{\\vec{y}}{\\vec{z}} \\delta\\vec{y} =\\mattr{R}\\mat{K^{-1}}\\delta\\vec{y}.\n",
    "$$\n",
    "\n",
    "We'll do the calculation in two steps:\n",
    "1. Calculate $\\delta\\vec{u}=\\mat{K}^{-1}\\delta\\vec{y}$: Equivalent to solving the linear system $\\mat{K}\\delta\\vec{u}=\\delta\\vec{y}$.\n",
    "2. Calculate $\\delta\\vec{z} = -\\mat{R}^\\top \\delta\\vec{u}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, based on this, we have a way to implement such an inner-optimization layer:\n",
    "\n",
    "**Forward pass**: Compute the optimal solution of the inner problem, either with a some solver or even a closed-form expression.\n",
    "\n",
    "**Backward pass**: Calculate $\\delta\\vec{z}$ using the two-step procedure described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ls(A: Tensor, B: Tensor, abs: float = 1e-6, rel: float = 1e-6) -> Tensor:\n",
    "    \"\"\"\n",
    "    Solve least squares fit AX=B using SVD and returns X\n",
    "    :param abs: Absolute threshold to reject small eigenvalues.\n",
    "    :param rel: Relative threshold to reject small eigenvalues.\n",
    "    \"\"\"\n",
    "    U, S, V = torch.svd(A)\n",
    "    th = max(rel * S[0].item(), abs)\n",
    "    # th = torch.max(rel * S[..., 0], torch.tensor(abs))\n",
    "    Sinv = torch.where(S >= th, 1.0 / S, torch.zeros_like(S))\n",
    "    return V @ torch.diag(Sinv) @ (U.transpose(1, 0) @ B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(*z: Tensor):\n",
    "    flat_z = torch.cat([z_.view(-1) for z_ in z], dim=0)\n",
    "    return flat_z\n",
    "\n",
    "def unflatten_like(t_flat: Tensor, *z: Tensor):\n",
    "    t_flat = t_flat.view(-1) # make sure it's 1d\n",
    "    ts = []\n",
    "    offset = 0\n",
    "    for z_ in z:\n",
    "        numel = z_.numel()\n",
    "        ts.append(\n",
    "            t_flat[offset:offset+numel].view_as(z_)\n",
    "        )\n",
    "        offset += numel\n",
    "    assert offset == t_flat.numel()\n",
    "    \n",
    "    return tuple(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1314, -0.0325,  0.7559,  0.5041, -2.4287, -0.5212, -1.2013,  0.9900,\n",
       "         0.9652,  0.1030,  1.4274,  0.1940, -1.1418,  0.3150, -0.3024,  0.4177,\n",
       "         2.0186, -0.8440,  0.3654, -0.0769,  0.3944, -2.9447, -0.4860])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = torch.randn(3, 5), torch.randn(2, 4)\n",
    "t_flat = flatten(t1, t2)\n",
    "t_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_, t2_ = unflatten_like(t_flat, t1, t2)\n",
    "assert torch.allclose(t1, t1_)\n",
    "assert torch.allclose(t2, t2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import LBFGS\n",
    "\n",
    "def argmin_forward(ctx, obj_fun, y, *z):\n",
    "    \n",
    "    optimizer = LBFGS(params=(y,), lr=0.1, max_iter=1000)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    def _optimizer_step():\n",
    "        # zero gradients\n",
    "        y.grad = torch.zeros_like(y)\n",
    "        # evaluate loss\n",
    "        f = obj_fun(y, *z)\n",
    "        # calculate gradients\n",
    "        # Note: not calling backward() because we don't want to compute\n",
    "        # gradients for anything except y\n",
    "        δy = autograd.grad(f, (y,), create_graph=False,)[0]\n",
    "        y.grad += δy\n",
    "        return f\n",
    "\n",
    "    f_min = optimizer.step(_optimizer_step,)\n",
    "    y_argmin = y # optimized in place\n",
    "\n",
    "    ctx.save_for_backward(y_argmin, *z)\n",
    "    ctx.obj_fun = obj_fun\n",
    "\n",
    "    return y_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import hessian\n",
    "\n",
    "def argmin_backward(ctx, grad_output):\n",
    "    y_argmin, *z = ctx.saved_tensors\n",
    "    obj_fun = ctx.obj_fun\n",
    "\n",
    "    print(f'*** Argmin Backward ***')\n",
    "\n",
    "    # Hessians\n",
    "    flat_y = flatten(y_argmin)\n",
    "    flat_z = flatten(*z)\n",
    "    print(f'*** {flat_z.shape=}')\n",
    "    \n",
    "    def obj_fun_flat(flat_y, flat_z):\n",
    "        # Wrap objective so that we can call it with flat tensors\n",
    "        y = unflatten_like(flat_y, y_argmin)\n",
    "        zs = unflatten_like(flat_z, *z)\n",
    "        return obj_fun(*y, *zs)\n",
    "    \n",
    "    H = hessian(obj_fun_flat, inputs=(flat_y, flat_z), create_graph=False)\n",
    "    Hyy = K = H[0][0]\n",
    "    Hyz = R = H[0][1]\n",
    "    print(f'{K.shape=}, {R.shape=}')\n",
    "\n",
    "    # Now we need to calculate δz = -R^T K^-1 δy\n",
    "    # 1. Solve system for δu: K δu = δy\n",
    "    δy = grad_output\n",
    "    print(f'{δy.shape=}') \n",
    "\n",
    "    δy = torch.reshape(δy, (-1, 1))\n",
    "    δu = solve_ls(K, δy) # solve_ls(A, B) solves A X = B\n",
    "    print(f'{δu.shape=}') \n",
    "\n",
    "    # 2. Calculate δz = -R^T δu\n",
    "    δz_flat = -R.transpose(0, 1) @ δu\n",
    "    print(f'{δz_flat.shape=}') \n",
    "    \n",
    "    # Extract gradient of each individual z\n",
    "    # δz = torch.reshape(δz, z.shape)\n",
    "    print(f'***\\n{δz_flat=}')\n",
    "    print(f'***\\n{δz_flat.shape=}')\n",
    "    print(f'***\\n{z=}')\n",
    "    δz = unflatten_like(δz_flat, *z)\n",
    "    print(f'***')\n",
    "\n",
    "    δy = torch.reshape(δy, y_argmin.shape)\n",
    "    print(f'###')\n",
    "\n",
    "    return None, δy, *δz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgMinFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, obj_fun, y, *z):\n",
    "        return argmin_forward(ctx, obj_fun, y, *z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return argmin_backward(ctx, grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=torch.Size([100, 10]), y.shape=torch.Size([100]), w_gt.shape=torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "N, D = 100, 10\n",
    "\n",
    "X, y, w_gt = make_regression(\n",
    "    n_samples=N, n_features=D, coef=True, random_state=42, bias=10, noise=1,\n",
    ")\n",
    "\n",
    "X, y, w_gt = [ torch.from_numpy(t).to(torch.float64) for t in [X, y, w_gt] ]\n",
    "\n",
    "print(f\"{X.shape=}, {y.shape=}, {w_gt.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36505.2324, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def obj_fun(w: Tensor, l1: Tensor, l2: Tensor):\n",
    "    loss = torch.mean((X @ w - y)**2)\n",
    "    reg1 = l1 * torch.mean(torch.abs(w))\n",
    "    reg2 = l2 * torch.mean(w ** 2)\n",
    "    return torch.sum(loss + reg1 + reg2)\n",
    "\n",
    "obj_fun(\n",
    "    w=torch.randn_like(w_gt, requires_grad=True),\n",
    "    l1=torch.randn(1, 1, requires_grad=True),\n",
    "    l2=torch.randn(1, 1, requires_grad=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.norm(w_gt-w)=tensor(184.5435, grad_fn=<NormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([16.9955, 50.8658,  3.4545, 58.4062, 84.4079, 68.8225, 80.5330,  5.9484,\n",
       "         5.0106, 63.7150], grad_fn=<ArgMinFunctionBackward>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=torch.randn_like(w_gt, requires_grad=True)\n",
    "l1=torch.randn(1, requires_grad=True)\n",
    "l2=torch.randn(1, requires_grad=True)\n",
    "print(f'{torch.norm(w_gt-w)=}')\n",
    "\n",
    "w_argmin = ArgMinFunction.apply(obj_fun, w, l1, l2)\n",
    "w_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.7462, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(w_gt-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(438.1594, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.sum(w_argmin)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.grad=tensor([-1.8944e-05, -3.6243e-05, -6.1208e-06, -4.4747e-05, -5.1763e-05,\n",
      "        -6.5553e-05, -6.8470e-05,  2.3221e-05, -1.2681e-05, -4.4842e-05])\n",
      "l1.grad=None\n",
      "l2.grad=None\n"
     ]
    }
   ],
   "source": [
    "print(f'{w.grad=}')\n",
    "print(f'{l1.grad=}')\n",
    "print(f'{l2.grad=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Argmin Backward ***\n",
      "*** flat_z.shape=torch.Size([2])\n",
      "K.shape=torch.Size([10, 10]), R.shape=torch.Size([10, 2])\n",
      "δy.shape=torch.Size([10])\n",
      "δu.shape=torch.Size([10, 1])\n",
      "δz_flat.shape=torch.Size([2, 1])\n",
      "***\n",
      "δz_flat=tensor([[0.],\n",
      "        [0.]])\n",
      "***\n",
      "δz_flat.shape=torch.Size([2, 1])\n",
      "***\n",
      "z=[tensor([-1.3187], requires_grad=True), tensor([0.8362], requires_grad=True)]\n",
      "***\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.grad=tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "l1.grad=tensor([0.])\n",
      "l2.grad=tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(f'{w.grad=}')\n",
    "print(f'{l1.grad=}')\n",
    "print(f'{l2.grad=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"422pt\" height=\"152pt\"\n",
       " viewBox=\"0.00 0.00 422.00 152.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 148)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-148 418,-148 418,4 -4,4\"/>\n",
       "<!-- 140636305606064 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140636305606064</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"253.15,-20 160.85,-20 160.85,0 253.15,0 253.15,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 140636312965600 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140636312965600</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"279.77,-76 134.23,-76 134.23,-56 279.77,-56 279.77,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\">ArgMinFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 140636312965600&#45;&gt;140636305606064 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140636312965600&#45;&gt;140636305606064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M207,-55.59C207,-48.7 207,-39.1 207,-30.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.5,-30.3 207,-20.3 203.5,-30.3 210.5,-30.3\"/>\n",
       "</g>\n",
       "<!-- 140636302222144 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140636302222144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-144 0,-144 0,-112 54,-112 54,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-130.4\" font-family=\"Times,serif\" font-size=\"12.00\">w</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140636302222144&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140636302222144&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.02,-115.43C57.04,-114.23 60.07,-113.06 63,-112 97.13,-99.59 136.53,-87.42 165.48,-78.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.65,-82.18 175.26,-76.01 164.68,-75.46 166.65,-82.18\"/>\n",
       "</g>\n",
       "<!-- 140636302224592 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140636302224592</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"126,-144 72,-144 72,-112 126,-112 126,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-130.4\" font-family=\"Times,serif\" font-size=\"12.00\">l1</text>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140636302224592&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140636302224592&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M126.25,-111.86C143.18,-102.46 164.79,-90.45 181.4,-81.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.48,-84.07 190.52,-76.15 180.08,-77.95 183.48,-84.07\"/>\n",
       "</g>\n",
       "<!-- 140636302222096 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140636302222096</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"198,-144 144,-144 144,-112 198,-112 198,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-130.4\" font-family=\"Times,serif\" font-size=\"12.00\">l2</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140636302222096&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140636302222096&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.08,-111.86C184.99,-103.69 191.07,-93.55 196.21,-84.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.36,-86.53 201.51,-76.15 193.36,-82.93 199.36,-86.53\"/>\n",
       "</g>\n",
       "<!-- 140636302095680 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140636302095680</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"270,-138 216,-138 216,-118 270,-118 270,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-124.4\" font-family=\"Times,serif\" font-size=\"12.00\">(10)</text>\n",
       "</g>\n",
       "<!-- 140636302095680&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140636302095680&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.53,-117.89C232.3,-109.17 224.26,-95.77 217.74,-84.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.67,-82.97 212.52,-76.2 214.66,-86.57 220.67,-82.97\"/>\n",
       "</g>\n",
       "<!-- 140636300466304 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140636300466304</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"342,-138 288,-138 288,-118 342,-118 342,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-124.4\" font-family=\"Times,serif\" font-size=\"12.00\">(1)</text>\n",
       "</g>\n",
       "<!-- 140636300466304&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140636300466304&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.6,-117.89C280.89,-108.05 252.48,-92.27 231.99,-80.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.64,-77.8 223.2,-76 230.25,-83.92 233.64,-77.8\"/>\n",
       "</g>\n",
       "<!-- 140636297526912 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140636297526912</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"414,-138 360,-138 360,-118 414,-118 414,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"387\" y=\"-124.4\" font-family=\"Times,serif\" font-size=\"12.00\">(1)</text>\n",
       "</g>\n",
       "<!-- 140636297526912&#45;&gt;140636312965600 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140636297526912&#45;&gt;140636312965600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M366.19,-117.95C361.24,-115.9 355.96,-113.81 351,-112 316.87,-99.59 277.47,-87.42 248.52,-78.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.32,-75.46 238.74,-76.01 247.35,-82.18 249.32,-75.46\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe87109c7c0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchviz.make_dot(torch.sum(ArgMinFunction.apply(obj_fun, w, l1, l2)), params={'w':w,'l1':l1,'l2':l2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Image credits**\n",
    "\n",
    "Some images in this tutorial were taken and/or adapted from:\n",
    "\n",
    "- Dr. Roger Grosse, UToronto, cs321\n",
    "- Fundamentals of Deep Learning, Nikhil Buduma, Oreilly 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
