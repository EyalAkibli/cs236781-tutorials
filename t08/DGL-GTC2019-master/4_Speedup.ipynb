{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed up GNN training\n",
    "===================\n",
    "In previous tutorial (GCN.ipynb), we have seen how to implement an end-to-end GCN model for community detection with DGL. \n",
    "\n",
    "Despite the fact that training looks fast in previous example, it's only because the graph is small (34 nodes, 190 edges) and the node feature is just a scalar. In reality, we will always be dealing with large graphs which could have more than millions of nodes and edges, each associated large features.\n",
    "\n",
    "There are two challenges for making computation over graph efficient:\n",
    "- nodes in graphs have different degrees (power-law distribution usually), and the best we can do is batch reduce functions by in-degree of nodes\n",
    "- number of edges is usually one order of magnitude larger than nodes, and materialized messages that are stored on edges consume huge amount of memory\n",
    "\n",
    "Therefore, when training GNN models on large graphs, people always easily get slow training speed or even an out-of-memory error. And this tutorial provides some optimization guideline about how to write GNN model efficiently with DGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup, just ignore this cell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['animation.html'] = 'html5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuse message reduction into one kernel\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "To address the first challenge, DGL exploits the fact that if the reduce function is a summation, the reduce phase can be replaced with a sparse matrix dense vector multiplication (SPMV) between messages and [incidence matrix](https://en.wikipedia.org/wiki/Incidence_matrix), as illustrated below:\n",
    "![](https://www.dropbox.com/s/cditivsb50w2i5c/fuse_reduce.png?dl=1)\n",
    "\n",
    "In the figure, $M_{ij}$ represents message sent from node $i$ to node $j$, and $M_i$ represents aggregated messages that node $i$ received. The incidence matrix is a sparse matrix that encodes connectivity between edges and destination node. Each row in the graph represents a destination node, and each column represents an edge. If the value at location $(i, j)$ has value $1$, then edge $j$'s destination end is node $i$.\n",
    "\n",
    "By replacing reduce phase with a simple sparse matrix multiplication kernel, DGL avoids the cost to \n",
    "- analyze graph structure and assign receive nodes to execution buckets based on node in-degree\n",
    "- loop over each degree bucket and perform reduce\n",
    "- merge results of each degree buckets\n",
    "\n",
    "To enable this optimization, DGL requires users to provide hints about the reduce function. We provide many commonly used builtin reduce functions like `sum`, `max`, which, on one hand, saves users' trouble to define reduce function, and on the other hand, informs DGL what reduce function is doing, so that optimization can be done.\n",
    "\n",
    "Now we can re-define the GCN model with SPMV reduce optimization, and DGL will automatically generate the sparse matrix for fused execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the message & reduce function\n",
    "# NOTE: we ignore the normalization constant c_ij for now.\n",
    "def gcn_message(edges):\n",
    "    # messages are the features of the source nodes.\n",
    "    return {'msg' : edges.src['h']}\n",
    "\n",
    "# Define the GCN module\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "    \n",
    "    def forward(self, g, inputs):\n",
    "        # g is the graph and the inputs is the input node features\n",
    "        # first perform linear transformation\n",
    "        h = self.linear(inputs)\n",
    "        # set the node features\n",
    "        g.ndata['h'] = h\n",
    "        # trigger message passing\n",
    "        g.send(g.edges(), gcn_message)\n",
    "        g.recv(g.nodes(), fn.sum('msg', 'h'))\n",
    "        # get the result node features\n",
    "        h = g.ndata.pop('h')\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuse message passing into one kernel\n",
    "The fusion of reduce into one kernel is already able to significantly reduce execution time. And if the message function is also some known pattern like copying out source node representation (DGL's builtin message function `copy_src`), it can also be fused with reduce function:\n",
    "![](https://www.dropbox.com/s/ws62v6ukjx968fb/fuse_mp.png?dl=1)\n",
    "\n",
    "Here the sparse matrix is the transpose of the adjacency matrix which encodes connectivity between nodes in graphs.\n",
    "\n",
    "In order to trigger the fusion of entire message passing, DGL needs to know both the message function and reduce function. DGL provides many routines that combines basic `send` and `recv` in various ways. They are called **level-2 APIs**. For example, we can use the `send_and_recv` API to trigger both message function and reduce function in one API. Furthermore, since GCN performs computation on the entire graph, we can use `update_all` API in the GCN module so that `edges()` and `nodes()` can be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the GCN module using DGL builtin functions and level-2 APIs.\n",
    "class GCN_level2(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCN_level2, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "    \n",
    "    def forward(self, g, inputs):\n",
    "        # g is the graph and the inputs is the input node features\n",
    "        # first perform linear transformation\n",
    "        h = self.linear(inputs)\n",
    "        # set the node features\n",
    "        g.ndata['h'] = h\n",
    "        # trigger message passing using `update_all`\n",
    "        # original codes:\n",
    "        #   g.send(g.edges(), gcn_message)\n",
    "        #   g.recv(g.nodes(), gcn_reduce)\n",
    "        g.update_all(fn.copy_src('h', 'msg'), fn.sum('msg', 'h'))\n",
    "        # get the result node features\n",
    "        h = g.ndata.pop('h')\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the GCN community detection model using `GCN_level2` and re-train it again on karate club graph from previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2-layer GCN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN_level2(in_feats, hidden_size)\n",
    "        self.gcn2 = GCN_level2(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, g, inputs):\n",
    "        h = self.gcn1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(g, h)\n",
    "        return h\n",
    "\n",
    "import dgl, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from tutorial_utils import create_karate_graph, convert_to_bidirectional\n",
    "G = create_karate_graph()\n",
    "GG = convert_to_bidirectional(G)\n",
    "    \n",
    "inputs = torch.eye(34)  # featureless inputs\n",
    "labeled_nodes = torch.tensor([0, 33])  # only the instructor and the president nodes are labeled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "net = Net(34, 5, 2)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for epoch in range(30):\n",
    "    logits = net(GG, inputs)\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for node 0 and node 33\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the node classification using the logits output.\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "fig.clf()\n",
    "ax = fig.subplots()\n",
    "nx_G = G.to_networkx()\n",
    "def draw(i):\n",
    "    cls1color = '#00FFFF'\n",
    "    cls2color = '#FF00FF'\n",
    "    pos = {}\n",
    "    colors = []\n",
    "    for v in range(34):\n",
    "        pos[v] = all_logits[i][v].numpy()\n",
    "        cls = np.argmax(pos[v])\n",
    "        colors.append(cls1color if cls else cls2color)\n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Epoch: %d' % i)\n",
    "    nx.draw(nx_G.to_undirected(), pos, node_color=colors, with_labels=True, node_size=500)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=200)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Writing GNN models with DGL's builtin message and reduce functions allows DGL to perform optimizations like fusing computation into one kernel.\n",
    "\n",
    "However, most GNN models are complicated with carefully designed message and reduce function, in which case, DGL's builtin won't be expressive enough. But in principle, users should try to push as much computation into message function and node apply function since they are usually perfectly parallelizable and keep reduce function as simple as possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
